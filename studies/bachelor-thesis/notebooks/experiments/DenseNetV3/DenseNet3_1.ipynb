{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b694919a-9b18-4068-8e69-7258de889dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_VLOG_LEVEL'] = '0'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "from src.utils.gpu_config import configure_gpu, optimize_tensorflow\n",
    "\n",
    "configure_gpu()\n",
    "optimize_tensorflow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b854daf-5f2a-4c33-9180-5081cd415b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Tensorflow Keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "# Import local modules\n",
    "from src.utils.consts import TF_RECORD_DATASET, MODELS_PATH, TF_BUFFER_SIZE, TF_SHUFFLE_SIZE, TF_BATCH_SIZE, TF_MAX_EPOCHS\n",
    "from src.model.tensorflow_utils import load_dataset, optimize_dataset, count_dataset_size, get_num_classes, get_metrics\n",
    "from src.model.tensorflow_utils import setup_logger, setup_training_logger, setup_metrics_monitor, setup_early_stopping, filter_no_finding_class\n",
    "from src.model.tensorflow_utils import start_or_resume_training, apply_augmentation_to_dataset, calculate_class_weights, oversample_minority_classes\n",
    "from src.model.densnet.tensorflow_dense_net_121 import build_densenet121\n",
    "\n",
    "# Input Data\n",
    "initial_epoch   = None\n",
    "resume_training = False\n",
    "checkpoint_path = None\n",
    "set_name        = \"DenseNetV2\"\n",
    "model_name      = f\"{set_name}_4\"\n",
    "num_classes     = get_num_classes()\n",
    "\n",
    "train_ds = load_dataset(f\"{TF_RECORD_DATASET}/train.tfrecord\", TF_BUFFER_SIZE)\n",
    "val_ds   = load_dataset(f\"{TF_RECORD_DATASET}/val.tfrecord\", TF_BUFFER_SIZE)\n",
    "\n",
    "train_ds = filter_no_finding_class(train_ds)\n",
    "val_ds   = filter_no_finding_class(val_ds)\n",
    "\n",
    "class_weights = calculate_class_weights(train_ds, num_classes)\n",
    "train_ds      = oversample_minority_classes(train_ds, class_weights)\n",
    "class_weights = calculate_class_weights(train_ds, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f152b8a-8ff8-4095-9815-e304ce2beb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch  = int((104166 or int(count_dataset_size(train_ds, None))) / TF_BATCH_SIZE)\n",
    "validation_steps = int((15431 or int(count_dataset_size(val_ds, None))) / TF_BATCH_SIZE)\n",
    "\n",
    "# Disable Advanced Augmentations\n",
    "probability = {\n",
    "    \"intensity_scaling\": 0,\n",
    "    \"adaptive_histogram\": 0,\n",
    "    \"zoom\": 0,\n",
    "    \"cutout\": 0\n",
    "}\n",
    "\n",
    "train_ds = train_ds.shuffle(TF_SHUFFLE_SIZE, reshuffle_each_iteration=True)\n",
    "train_ds = apply_augmentation_to_dataset(train_ds, probability)\n",
    "train_ds = optimize_dataset(train_ds, TF_BATCH_SIZE)\n",
    "\n",
    "val_ds   = optimize_dataset(val_ds, TF_BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0e37c9-b178-40d8-bd25-8c0a6498564a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Model Deps\n",
    "logger            = setup_logger()\n",
    "training_logger   = setup_training_logger(logger, TF_BATCH_SIZE, 100)\n",
    "metrics_monitor   = setup_metrics_monitor(MODELS_PATH, model_name, logger, resume_training=resume_training, initial_epoch=initial_epoch)\n",
    "metrics           = get_metrics()\n",
    "\n",
    "# Setup compile arguments\n",
    "loss           = BinaryCrossentropy(from_logits=False, label_smoothing=0.01)\n",
    "reduce_lr      = ReduceLROnPlateau(monitor=\"val_f1_score\", factor=0.5,  patience=3, min_lr=1e-6, mode=\"max\", verbose=1)\n",
    "early_stopping = setup_early_stopping()\n",
    "\n",
    "epoch_mode           = 'cp-{epoch:04d}'\n",
    "save_checkpoint_path = f\"{MODELS_PATH}/{model_name}/checkpoints/{epoch_mode}.keras\"\n",
    "checkpoint           = ModelCheckpoint(save_checkpoint_path, monitor=\"val_f1_score\", save_best_only=False, mode=\"max\", save_weights_only=False)\n",
    "\n",
    "model_path      = f\"{MODELS_PATH}/{model_name}.keras\"\n",
    "best_checkpoint = ModelCheckpoint(model_path, monitor=\"val_f1_score\", save_best_only=True, mode=\"max\", save_weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d4a9a-ffbb-4917-a702-c35773b9857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training\n",
    "model          = build_densenet121(num_classes)\n",
    "optimizer      = Adam(learning_rate=1e-4)\n",
    "compile_kwargs = {'optimizer': optimizer, 'loss': loss, 'metrics': metrics}\n",
    "\n",
    "history, model = start_or_resume_training(\n",
    "    model, \n",
    "    compile_kwargs, \n",
    "    train_ds, \n",
    "    val_ds, \n",
    "    TF_MAX_EPOCHS,\n",
    "    steps_per_epoch, \n",
    "    validation_steps, \n",
    "    class_weights=class_weights,\n",
    "    callbacks=[checkpoint, best_checkpoint, reduce_lr, training_logger, metrics_monitor, early_stopping], \n",
    "    checkpoint_path=checkpoint_path,\n",
    "    initial_epoch=initial_epoch,\n",
    "    output_dir=MODELS_PATH,\n",
    "    model_name=model_name,\n",
    "    logger=logger\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
