{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6bc1709-f52b-4311-9dff-25e27e42c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "nih_dataset = '../data/nih-dataset'\n",
    "cleared_dataset = '../cleared-data/nih-dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64fab830-6c93-4281-90e9-c3025a52b61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patients Age Clearing\n",
    "# Reload the dataset\n",
    "data_entry_file = f'{nih_dataset}/Data_Entry_2017.csv'\n",
    "data_frame = pd.read_csv(data_entry_file, delimiter=',', nrows=None)\n",
    "\n",
    "total_count = len(data_frame)\n",
    "\n",
    "# Group by Patient ID and get the first age for each patient\n",
    "unique_patients = data_frame.groupby('Patient ID')['Patient Age'].first()\n",
    "\n",
    "# Calculate mean and standard deviation of ages\n",
    "mean_unique_age = unique_patients.mean()\n",
    "std_dev_unique_age = unique_patients.std()\n",
    "\n",
    "# Define outlier thresholds - age\n",
    "outlier_threshold_upper_std = round(mean_unique_age + 3 * std_dev_unique_age, 4)\n",
    "outlier_threshold_lower_std = 0 # Can't be younger than 0 years \n",
    "\n",
    "# Patients in age between [0 and 3σ]\n",
    "filtered_unique_patients = unique_patients[\n",
    "    (unique_patients >= outlier_threshold_lower_std) & \n",
    "    (unique_patients <= outlier_threshold_upper_std)\n",
    "]\n",
    "\n",
    "filtered_unique_patients = filtered_unique_patients.reset_index()\n",
    "valid_patient_ids = filtered_unique_patients['Patient ID'].tolist()\n",
    "filtered_data = data_frame[data_frame['Patient ID'].isin(valid_patient_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84138dc-5394-4bc9-9a1a-e99b86213e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling Clearing\n",
    "# Reload the dataset\n",
    "total_size = len(filtered_data)\n",
    "\n",
    "dominant_class = \"No Finding\"\n",
    "dominant_class_data = filtered_data[filtered_data['Finding Labels'] == dominant_class]\n",
    "minority_classes_data = filtered_data[filtered_data['Finding Labels'] != dominant_class]\n",
    "\n",
    "assert total_size == len(dominant_class_data) + len(minority_classes_data)\n",
    "\n",
    "undersample_rate = round(len(minority_classes_data) / len(dominant_class_data), 2)\n",
    "undersample_size = int(len(dominant_class_data) * undersample_rate)\n",
    "\n",
    "balanced_dominant_class = dominant_class_data.sample(n=undersample_size, random_state=42)\n",
    "balanced_data = pd.concat([balanced_dominant_class, minority_classes_data], ignore_index=True)\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5514460-a41c-42fa-905e-8fc6375d1129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in cleated Dataset\n",
    "cleared_data_enetry = f'{cleared_dataset}/Data_Entry_2017.csv'\n",
    "balanced_data.to_csv(cleared_data_enetry, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad15c1a8-7511-4a67-8a35-c376e9a9a402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W: 759.22, H: 730.63\n",
      "Original dataset size: 985\n",
      "Filtered dataset size: 973\n",
      "Data lose: 12\n",
      "Data lose ration: 1.22 \n"
     ]
    }
   ],
   "source": [
    "# Prepare Bounding Box Data\n",
    "data_entry_file = f'{nih_dataset}/BBox_List_2017.csv'\n",
    "bbox_data = pd.read_csv(data_entry_file, delimiter=',', nrows=None)\n",
    "renamed_bbox_data = bbox_data.dropna(axis=1, how='all').copy()\n",
    "renamed_bbox_data.rename(columns={\"Bbox [x\": \"x\", \"h]\": \"h\"}, inplace=True)\n",
    "\n",
    "# Calculage widh & heigh data bounds\n",
    "mean_w = renamed_bbox_data['w'].mean()\n",
    "std_w = renamed_bbox_data['w'].std()\n",
    "mean_h = renamed_bbox_data['h'].mean()\n",
    "std_h = renamed_bbox_data['h'].std()\n",
    "w_outlier_threshold = round(mean_w + 3 * std_w, 2)\n",
    "h_outlier_threshold = round(mean_h + 3 * std_h, 2)\n",
    "\n",
    "print(f\"W: {w_outlier_threshold}, H: {h_outlier_threshold}\")\n",
    "\n",
    "filtered_bbox_data = renamed_bbox_data[\n",
    "    (renamed_bbox_data['w'] <= w_outlier_threshold) & \n",
    "    (renamed_bbox_data['h'] <= h_outlier_threshold)\n",
    "]\n",
    "\n",
    "print(f\"Original dataset size: {len(renamed_bbox_data)}\")\n",
    "print(f\"Filtered dataset size: {len(filtered_bbox_data)}\")\n",
    "print(f\"Data lose: {len(renamed_bbox_data) - len(filtered_bbox_data)}\")\n",
    "print(f\"Data lose ration: {round(100 - (len(filtered_bbox_data) / len(renamed_bbox_data)) * 100,2)} \")\n",
    "\n",
    "# Store in cleated Dataset\n",
    "cleared_data_enetry = f'{cleared_dataset}/BBox_List_2017.csv'\n",
    "filtered_bbox_data.to_csv(cleared_data_enetry, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c9ae87-9011-491f-8549-9a6a950e0489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path intensity  ssim\n",
      "0  ../data/nih-dataset/images_011/images/00026083...      None  None\n",
      "1  ../data/nih-dataset/images_002/images/00003274...      None  None\n",
      "2  ../data/nih-dataset/images_005/images/00009320...      None  None\n",
      "3  ../data/nih-dataset/images_010/images/00022931...      None  None\n",
      "4  ../data/nih-dataset/images_002/images/00003535...      None  None\n"
     ]
    }
   ],
   "source": [
    "# Images Data Clearing\n",
    "from PIL import Image\n",
    "import re\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "pattern = re.compile(r'images_\\d{3}')\n",
    "matching_dirs = [\n",
    "    os.path.join(nih_dataset, d)\n",
    "    for d in os.listdir(nih_dataset)\n",
    "    if os.path.isdir(os.path.join(nih_dataset, d)) and pattern.match(d)\n",
    "]\n",
    "\n",
    "image_files = set()\n",
    "for directory in matching_dirs:\n",
    "    nested_dir = f\"{directory}/images\"\n",
    "    image_files_in_dir = os.listdir(nested_dir)\n",
    "    for image in image_files_in_dir:\n",
    "        image_path = os.path.join(nested_dir, image)\n",
    "        image_files.add(image_path)\n",
    "\n",
    "images_df = pd.DataFrame(list(image_files))\n",
    "images_df.columns = ['image_path']\n",
    "images_df['intensity'] = None\n",
    "images_df['ssim'] = None\n",
    "print(images_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a204f438-5dbf-41a5-8980-5341b73cd84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|█▏                                                                                                                                  | 1059/112120 [00:07<13:56, 132.73it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 13\u001b[0m     images_df\u001b[38;5;241m.\u001b[39mat[index, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mintensity\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_pixel_intensity_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     15\u001b[0m     tqdm\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError processing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m, in \u001b[0;36mcalculate_pixel_intensity_stats\u001b[0;34m(image_file)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcalculate_pixel_intensity_stats\u001b[39m(image_file):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Image\u001b[38;5;241m.\u001b[39mopen(image_file) \u001b[38;5;28;01mas\u001b[39;00m img:\n\u001b[0;32m----> 5\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)  \u001b[38;5;66;03m# Convert to NumPy array\u001b[39;00m\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img_array\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/PIL/Image.py:984\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;15\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;16\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBGR;24\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    982\u001b[0m     deprecate(mode, \u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m--> 984\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    986\u001b[0m has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    987\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    988\u001b[0m     \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.asdf/installs/python/3.11.0/lib/python3.11/site-packages/PIL/ImageFile.py:300\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    299\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 300\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Filter by intensity\n",
    "\n",
    "def calculate_pixel_intensity_stats(image_file):\n",
    "    with Image.open(image_file) as img:\n",
    "        img = img.convert('L')\n",
    "        img_array = np.array(img, dtype=np.float32)  # Convert to NumPy array\n",
    "        return img_array.mean()\n",
    "            \n",
    "intensities = []\n",
    "for index, row in tqdm(images_df.iterrows(), total=len(images_df)):\n",
    "    try:\n",
    "        image_path = row['image_path']\n",
    "        images_df.at[index, 'intensity'] = calculate_pixel_intensity_stats(image_path)\n",
    "    except Exception as e:\n",
    "        tqdm.write(f\"Error processing {image}: {e}\")\n",
    "        continue\n",
    "\n",
    "mean_intensity = np.mean(images_df['intensity'])\n",
    "std_intensity = np.std(images_df['intensity'])\n",
    "\n",
    "mean_intensity_upper_outlier = round(mean_intensity + 3 * std_intensity, 4)\n",
    "mean_intensity_lower_outlier = round(mean_intensity - 3 * std_intensity, 4)\n",
    "\n",
    "print(\"Upper Outlier Threshold:\", mean_intensity_upper_outlier)\n",
    "print(\"Lower Outlier Threshold:\", mean_intensity_lower_outlier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134ebe60-6e58-4100-849f-dd5a9ef68ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images_df = images_df[\n",
    "    (images_df['intensity'] >= mean_intensity_lower_outlier) &\n",
    "    (images_df['intensity'] <= mean_intensity_upper_outlier)\n",
    "]\n",
    "\n",
    "print(f\"Final dataset size before removing outliers: {len(images_df)}\")\n",
    "print(f\"Final dataset size after removing outliers: {len(filtered_images_df)}\")\n",
    "print(f\"Dataset size diff: {len(images_df) - len(filtered_images_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234d64c6-a7d3-4ae4-bbe6-67e750ae7fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as ssim\n",
    "median_intensity = np.median(filtered_images_df['intensity'])\n",
    "closest_image_index = np.argmin([abs(intensity - median_intensity) for intensity in filtered_images_df['intensity']])\n",
    "\n",
    "print(f\"Median intensity: {median_intensity}\")\n",
    "print(f\"Closest image index: {closest_image_index}\")\n",
    "print(f\"Closest image intensity: {filtered_images_df.iloc[closest_image_index]['intensity']}\")\n",
    "\n",
    "reference_image_path = filtered_images_df.iloc[closest_image_index]['images_path']\n",
    "reference_image = Image.open(reference_image_path).convert(\"L\")\n",
    "reference_image = np.array(reference_image)  # Konwersja do NumPy\n",
    "\n",
    "for index, row in tqdm(filtered_images_df.iterrows(), total=len(filtered_images_df)):\n",
    "    try:\n",
    "        comparison_image = Image.open(row['images_path']).convert(\"L\")\n",
    "        comparison_image = np.array(comparison_image)\n",
    "\n",
    "        if reference_image.shape != comparison_image.shape:\n",
    "            comparison_image = Image.fromarray(comparison_image).resize(\n",
    "                (reference_image.shape[1], reference_image.shape[0]), Image.LANCZOS\n",
    "            )\n",
    "            comparison_image = np.array(comparison_image)\n",
    "\n",
    "        ssim_value, _ = ssim(reference_image, comparison_image, full=True)\n",
    "        filtered_images_df.at[index, 'ssim'] = ssim_value\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd przetwarzania {image_path}: {e}\")\n",
    "\n",
    "print(filtered_images_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "263ac67b-97bb-4be6-b3f6-bc59c9a4e3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upper Outlier Threshold: 0.8236\n",
      "Lower Outlier Threshold: 0.4617\n",
      "Final dataset size before removing outliers: 111822\n",
      "Final dataset size after removing outliers: 110999\n",
      "Dataset size diff: 823\n"
     ]
    }
   ],
   "source": [
    "# Ensure SSIM is numeric\n",
    "filtered_images_df['ssim'] = pd.to_numeric(filtered_images_df['ssim'], errors='coerce')\n",
    "\n",
    "# Compute mean and standard deviation\n",
    "mean_ssim = np.mean(filtered_images_df['ssim'])\n",
    "std_ssim = np.std(filtered_images_df['ssim'])\n",
    "\n",
    "# Define outlier thresholds\n",
    "mean_ssim_upper_outlier = round(mean_ssim + 3 * std_ssim, 4)\n",
    "mean_ssim_lower_outlier = round(mean_ssim - 3 * std_ssim, 4)\n",
    "\n",
    "print(\"Upper Outlier Threshold:\", mean_ssim_upper_outlier)\n",
    "print(\"Lower Outlier Threshold:\", mean_ssim_lower_outlier)\n",
    "\n",
    "# Corrected filtering condition (inside the range, not outside)\n",
    "simm_images_df = filtered_images_df[\n",
    "    (filtered_images_df['ssim'] <= mean_ssim_upper_outlier) &  # Inside upper limit\n",
    "    (filtered_images_df['ssim'] >= mean_ssim_lower_outlier)    # Inside lower limit\n",
    "]\n",
    "\n",
    "print(f\"Final dataset size before removing outliers: {len(filtered_images_df)}\")\n",
    "print(f\"Final dataset size after removing outliers: {len(simm_images_df)}\")\n",
    "print(f\"Dataset size diff: {len(filtered_images_df) - len(simm_images_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc7a3561-8bc7-47ce-9dc0-83df24b0f690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 110999/110999 [01:59<00:00, 932.07it/s]\n"
     ]
    }
   ],
   "source": [
    "# Save cleared data copy\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Define source and destination folders\n",
    "images_dataset = f\"{cleared_dataset}/images\"\n",
    "os.makedirs(images_dataset, exist_ok=True)\n",
    "\n",
    "for index, row in tqdm(simm_images_df.iterrows(), total=len(simm_images_df)):\n",
    "    try:\n",
    "        image_path = row['images_path']\n",
    "        source_path = os.path.abspath(image_path)  # If paths are absolute in the DataFrame\n",
    "        destination_path = os.path.join(images_dataset, os.path.basename(image_path))\n",
    "\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.copy2(source_path, images_dataset)  # Preserve metadata\n",
    "        else:\n",
    "            tqdm.warning(f\"Warning: File not found - {source_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error copying {image_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d60e5bf-75b2-444b-b74b-1fb6444457bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09111e7a-e17d-4f33-a036-13515d426a87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
